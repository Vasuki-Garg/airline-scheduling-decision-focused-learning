# ============================================================
# Repo: Vasuki-Garg/airline-scheduling-decision-focused-learning
# Runs: dbb + nid + PSO (from src/pso.py)
# ============================================================

REPO_URL = "https://github.com/Vasuki-Garg/airline-scheduling-decision-focused-learning.git"
CSV_PATH = "to_change.csv" 

# 1) Install deps
!pip -q install pyepo gurobipy scipy tabulate scikit-learn torch matplotlib

# 2) Mount Drive
from google.colab import drive
drive.mount("/content/drive")

# 3) Clone repo
import os, shutil
REPO_DIR = "/content/airline-scheduling-decision-focused-learning"
if os.path.exists(REPO_DIR):
    shutil.rmtree(REPO_DIR)
!git clone {REPO_URL} {REPO_DIR}
%cd {REPO_DIR}

# 4) Imports
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader

import pyepo
from pyepo.data.dataset import optDataset
from pyepo.func import blackboxOpt, negativeIdentity

# from repo
from src import load_and_clean_csv, build_feature_matrix
from src.model import ASPmodel
from src.train_dfo import run_pipeline
from src.pso import run_pso, run_pso_hpo_for_model 

# 5) Load + preprocess
df = load_and_clean_csv(CSV_PATH, n_rows=500)
df, X = build_feature_matrix(df, feature_col="original_feats")
C = np.array(df["transit_times"].tolist())

x_train, x_test, c_train, c_test = train_test_split(X, C, test_size=0.2, random_state=42)

# 6) Build optimization model (one scenario row)
row = df.loc[df["time_window_hours"].idxmin()]
n_aircraft = len(df["transit_times"].iloc[0])

E = dict(zip(range(n_aircraft), [t - 60   for t in row["relative_transit_times"]]))
L = dict(zip(range(n_aircraft), [t + 1800 for t in row["relative_transit_times"]]))
T = dict(zip(range(n_aircraft), row["relative_transit_times"]))
sizes = dict(zip(range(n_aircraft), row["wtc"]))

optmodel = ASPmodel(n_aircraft, E, L, sizes, T)

# 7) Models
class SimpleRegression(nn.Module):
    def __init__(self, inp, out):
        super().__init__()
        self.linear = nn.Linear(inp, out)
    def forward(self, x):
        return self.linear(x)

class MLP(nn.Module):
    def __init__(self, inp, hid, out):
        super().__init__()
        self.layer1 = nn.Linear(inp, hid)
        self.relu = nn.ReLU()
        self.layer2 = nn.Linear(hid, out)
    def forward(self, x):
        return self.layer2(self.relu(self.layer1(x)))

inp = x_train.shape[-1]
out = c_train.shape[-1]

models = {
    "simple_regression": SimpleRegression(inp, out),
    "mlp": MLP(inp, 64, out),
}

# 8) dbb + nid
methods = {
    "dbb": blackboxOpt(optmodel, processes=2),
    "nid": negativeIdentity(optmodel, processes=2),
}

results, exp_dirs = run_pipeline(
    x_train=x_train, x_test=x_test,
    c_train=c_train, c_test=c_test,
    optmodel=optmodel,
    models=models,
    methods=methods,
    batch_size=32,
)

# 9) PSO (uses YOUR src/pso.py)
dataset_train = optDataset(optmodel, x_train, c_train)
dataset_test  = optDataset(optmodel, x_test,  c_test)
loader_train  = DataLoader(dataset_train, batch_size=32, shuffle=False)
loader_test   = DataLoader(dataset_test,  batch_size=32, shuffle=False)

w_values   = [0.4, 0.7, 0.9]
phi_values = [0.5, 1.5, 2.5]
pso_configs = [{"num_particles": 10, "max_iters": 10, "w": w, "c1": phi, "c2": phi}
               for w in w_values for phi in phi_values]

simple_factory = lambda: SimpleRegression(inp, out)
mlp_factory    = lambda: MLP(inp, 64, out)

best_simple_model, res_simple, cfg_simple, simple_test_regret, simple_all = run_pso_hpo_for_model(
    model_ctor=simple_factory,
    model_name="simple_regression",
    optmodel=optmodel,
    loader_train=loader_train,
    loader_test=loader_test,
    pso_configs=pso_configs
)

best_mlp_model, res_mlp, cfg_mlp, mlp_test_regret, mlp_all = run_pso_hpo_for_model(
    model_ctor=mlp_factory,
    model_name="mlp",
    optmodel=optmodel,
    loader_train=loader_train,
    loader_test=loader_test,
    pso_configs=pso_configs
)

results["simple_regression"]["pso_hpo"] = {
    "model_name": "simple_regression",
    "method_name": "pso_hpo",
    "loss_log": [float(x) for x in res_simple.history],
    "loss_log_regret": [float(x) for x in res_simple.history],
    "elapsed_time": float(res_simple.elapsed),
    "final_regret": float(simple_test_regret),
    "hyperparameters": cfg_simple,
}

results["mlp"]["pso_hpo"] = {
    "model_name": "mlp",
    "method_name": "pso_hpo",
    "loss_log": [float(x) for x in res_mlp.history],
    "loss_log_regret": [float(x) for x in res_mlp.history],
    "elapsed_time": float(res_mlp.elapsed),
    "final_regret": float(mlp_test_regret),
    "hyperparameters": cfg_mlp,
}

# 10) Summary
print("\nSaved dbb/nid outputs to:", exp_dirs["base"])
print("\n================ SUMMARY ================")
for mname, md in results.items():
    print(f"\nModel: {mname}")
    for method, r in md.items():
        print(f"  {method:8s}  final_regret={r['final_regret']:.4f}  elapsed={r['elapsed_time']:.1f}s")
        if "hyperparameters" in r:
            print("           hyperparams:", r["hyperparameters"])
